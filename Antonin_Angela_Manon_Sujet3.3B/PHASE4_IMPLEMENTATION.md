# ğŸ¯ Phase 4 : CamemBERT Multi-tÃ¢ches - IMPLÃ‰MENTÃ‰ âœ…

## ğŸ“‹ Ce qui a Ã©tÃ© crÃ©Ã©

### 1. Configuration (`src/models/config.py`) âœ…
- `ModelConfig` : Configuration du modÃ¨le (architecture, dropout, etc.)
- `TrainingConfig` : Configuration de l'entraÃ®nement (learning rates, batch size, etc.)
- Fonction `set_seed()` pour la reproductibilitÃ©
- Mappings des labels (EMOTION_LABELS, SENTIMENT_LABELS, IRONY_LABELS)

### 2. Architecture CamemBERT (`src/models/camembert_multitask.py`) âœ…
```
Texte â†’ CamemBERT (encodeur partagÃ©) â†’ [CLS] token
                                            â†“
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â†“           â†“           â†“
                            Ã‰motions    Sentiment    Ironie
                            (7 classes) (3 classes)  (2 classes)
```

**FonctionnalitÃ©s** :
- Encodeur CamemBERT prÃ©-entraÃ®nÃ©
- 3 tÃªtes de classification avec dropout
- Loss combinÃ©e pondÃ©rÃ©e : `1.0Ã—emotion + 0.5Ã—sentiment + 0.3Ã—irony`
- MÃ©thodes `predict()`, `freeze_encoder()`, `unfreeze_encoder()`
- ~110M paramÃ¨tres

### 3. Script d'entraÃ®nement (`src/training/train.py`) âœ…
**Classe `MultiTaskDataset`** :
- Dataset PyTorch personnalisÃ©
- Tokenization automatique avec CamemBERT

**Fonction `train_epoch()`** :
- EntraÃ®nement sur une Ã©poque
- Calcul des mÃ©triques (F1-Score, Accuracy)
- Support du gradient accumulation

**Fonction `validate()`** :
- Validation sur val set
- Sans gradient (mode eval)

**Fonction `train_model()` (principale)** :
- Chargement des donnÃ©es (train/val/test)
- CrÃ©ation des DataLoaders
- **Learning rates diffÃ©renciÃ©s** :
  - Encodeur : 2e-5 (fine-tuning doux)
  - TÃªtes : 1e-4 (entraÃ®nement from scratch)
- **Early stopping** : patience de 3 Ã©poques
- Sauvegarde du meilleur modÃ¨le
- Historique d'entraÃ®nement en JSON

### 4. Utilitaires (`src/training/utils.py`) âœ…
- `create_optimizer_with_layerwise_lr()` : Optimiseur avec LR diffÃ©renciÃ©s
- `create_scheduler()` : Scheduler avec warmup
- `load_checkpoint()` : Chargement de checkpoints
- `plot_training_history()` : Visualisation de l'entraÃ®nement
- `print_model_summary()` : RÃ©sumÃ© du modÃ¨le

### 5. Scripts prÃªts Ã  l'emploi âœ…

**`run_training.py`** :
```bash
python run_training.py
```
- Lance l'entraÃ®nement avec config par dÃ©faut
- Batch size 16, 5 Ã©poques, early stopping
- Sauvegarde dans `models/best_model.pt`

**`evaluate_model.py`** :
```bash
python evaluate_model.py
```
- Ã‰value le modÃ¨le sur le test set
- GÃ©nÃ¨re rapports de classification complets
- CrÃ©e matrices de confusion (3 tÃ¢ches)
- Sauvegarde graphiques dans `results/`

---

## ğŸš€ Comment utiliser

### 1. EntraÃ®ner le modÃ¨le
```bash
cd Antonin_Angela_Manon_Sujet3.3B
python run_training.py
```

**Sortie attendue** :
```
ğŸ–¥ï¸  Device: mps  # ou cuda ou cpu
ğŸ“‚ Chargement des donnÃ©es...
   âœ“ Train: 490 exemples
   âœ“ Val: 105 exemples
   âœ“ Test: 105 exemples
ğŸ“¥ Chargement de camembert-base...
âœ… ModÃ¨le crÃ©Ã© avec 110,549,767 paramÃ¨tres

ğŸš€ DÃ©but de l'entraÃ®nement (5 Ã©poques)
================================================================================

ğŸ“ Ã‰poque 1/5
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:45<00:00]
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00]

ğŸ“Š RÃ©sultats Ã‰poque 1:
   Train - Loss: 1.2345 | Emotion F1: 0.5234 | Sentiment Acc: 0.7123 | Irony F1: 0.6012
   Val   - Loss: 1.1234 | Emotion F1: 0.5678 | Sentiment Acc: 0.7456 | Irony F1: 0.6234

ğŸ’¾ Nouveau meilleur modÃ¨le ! Score: 0.6456
...
```

### 2. Ã‰valuer le modÃ¨le
```bash
python evaluate_model.py
```

**Sortie attendue** :
```
ğŸ¯ Ã‰VALUATION DU MODÃˆLE CAMEMBERT
ğŸ“¥ Chargement du modÃ¨le depuis models/best_model.pt...
âœ… ModÃ¨le chargÃ© avec succÃ¨s

ğŸ§ª Ã‰valuation sur le test set...

ğŸ“‹ RAPPORTS DE CLASSIFICATION
================================================================================

ğŸ­ Ã‰MOTIONS:
              precision    recall  f1-score   support
        joie     0.7500    0.8000    0.7742        15
   tristesse     0.6923    0.7500    0.7200        12
...

ğŸ’­ SENTIMENT:
              precision    recall  f1-score   support
    negatif     0.8500    0.8500    0.8500        40
...

ğŸ˜ IRONIE:
              precision    recall  f1-score   support
non_ironique     0.8750    0.9000    0.8873        80
...

ğŸ“Š Matrices de confusion sauvegardÃ©es: results/confusion_matrices.png
âœ… Ã‰valuation terminÃ©e !
```

---

## ğŸ“ Explications pÃ©dagogiques

### Pourquoi Learning Rates diffÃ©renciÃ©s ?

```python
optimizer = AdamW([
    {'params': encodeur, 'lr': 2e-5},     # Petit LR
    {'params': tÃªtes, 'lr': 1e-4}         # Grand LR
])
```

**Raison** :
- **Encodeur** : DÃ©jÃ  prÃ©-entraÃ®nÃ© sur des milliards de mots
  â†’ On veut juste le "fine-tuner" doucement (petit LR)
- **TÃªtes** : EntraÃ®nÃ©es from scratch pour nos tÃ¢ches
  â†’ On peut apprendre plus vite (grand LR)

### Pourquoi Loss pondÃ©rÃ©e ?

```python
loss = 1.0Ã—L_emotion + 0.5Ã—L_sentiment + 0.3Ã—L_irony
```

**Raison** :
- **Ã‰motions** (7 classes) : TÃ¢che la plus difficile â†’ poids 1.0
- **Sentiment** (3 classes) : Plus facile â†’ poids 0.5
- **Ironie** (2 classes) : La plus facile mais classes dÃ©sÃ©quilibrÃ©es â†’ poids 0.3

â†’ On Ã©quilibre l'importance des tÃ¢ches

### Pourquoi Early Stopping ?

```python
if val_score > best_val_score:
    save_model()
    patience_counter = 0
else:
    patience_counter += 1
    if patience_counter >= 3:
        stop_training()
```

**Raison** :
- Ã‰viter l'overfitting
- Si le modÃ¨le n'amÃ©liore plus pendant 3 Ã©poques â†’ arrÃªt
- On garde le meilleur modÃ¨le (pas le dernier !)

---

## ğŸ“Š RÃ©sultats attendus

### Objectifs de performance
- **Ã‰motions** : F1-Score â‰¥ 0.65 (objectif : 0.75)
- **Sentiment** : Accuracy â‰¥ 0.80 (objectif : 0.88)
- **Ironie** : F1-Score â‰¥ 0.60 (objectif : 0.70)

### Comparaison Baseline vs CamemBERT
| TÃ¢che | Baseline TF-IDF | CamemBERT (attendu) |
|-------|-----------------|---------------------|
| Ã‰motions F1 | ~0.50-0.55 | ~0.65-0.75 |
| Sentiment Acc | ~0.70-0.75 | ~0.80-0.88 |
| Ironie F1 | ~0.55-0.60 | ~0.60-0.70 |

**Gain attendu** : +10-15 points sur toutes les mÃ©triques ğŸš€

---

## ğŸ”§ Personnalisation

### Modifier les hyperparamÃ¨tres

Ã‰diter `run_training.py` :

```python
training_config = TrainingConfig(
    batch_size=8,           # Si problÃ¨mes mÃ©moire
    num_epochs=10,          # Plus d'Ã©poques
    lr_encoder=1e-5,        # LR plus petit
    lr_classifier=5e-5,     # LR plus petit
    patience=5,             # Plus de patience
    gradient_accumulation_steps=2  # Simuler batch_size=16
)
```

### Changer la pondÃ©ration des losses

Ã‰diter `run_training.py` :

```python
model_config = ModelConfig(
    loss_weight_emotion=1.0,
    loss_weight_sentiment=1.0,    # Ã‰quilibrÃ©
    loss_weight_irony=1.0
)
```

---

## âœ… Checklist Phase 4

- [x] Architecture CamemBERT implÃ©mentÃ©e
- [x] 3 tÃªtes de classification crÃ©Ã©es
- [x] Loss combinÃ©e pondÃ©rÃ©e
- [x] Dataset PyTorch custom
- [x] Boucle d'entraÃ®nement
- [x] Learning rates diffÃ©renciÃ©s
- [x] Early stopping
- [x] Sauvegarde checkpoints
- [x] Script d'Ã©valuation
- [x] Matrices de confusion
- [x] Rapports de classification
- [x] Documentation complÃ¨te

**â†’ Phase 4 : COMPLÃˆTE ! ğŸ‰**

---

## ğŸ“ Prochaines Ã©tapes (Phase 5)

1. **Lancer l'entraÃ®nement** : `python run_training.py`
2. **Analyser les rÃ©sultats** : Regarder les courbes d'apprentissage
3. **Ã‰valuer sur test** : `python evaluate_model.py`
4. **Analyse des erreurs** :
   - Identifier 50-100 exemples mal classÃ©s
   - Comprendre pourquoi (ironie non dÃ©tectÃ©e, contexte, etc.)
5. **Visualisations avancÃ©es** :
   - t-SNE des embeddings
   - Attention weights
6. **RÃ©diger le rapport final**

---

**Date de crÃ©ation** : 2 janvier 2026  
**Status** : âœ… IMPLÃ‰MENTÃ‰ ET PRÃŠT Ã€ L'EMPLOI
